{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "기차,중장비크롤링.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUseXFQsOYvy",
        "outputId": "a80ce618-637a-4c0a-e293-35361e8449c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XzRK0vcOZF9",
        "outputId": "1c2f3649-aea6-41e4-ccb8-db2e4e4bec4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
            "\u001b[K     |████████████████████████████████| 968 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 33.7 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 53.0 MB/s \n",
            "\u001b[?25hCollecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,660 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,484 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [945 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,262 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,098 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 11.7 MB in 3s (3,452 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 88.3 MB of archives.\n",
            "After this operation, 294 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 99.0.4844.51-0ubuntu0.18.04.1 [1,143 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 99.0.4844.51-0ubuntu0.18.04.1 [77.6 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 99.0.4844.51-0ubuntu0.18.04.1 [4,388 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 99.0.4844.51-0ubuntu0.18.04.1 [5,092 kB]\n",
            "Fetched 88.3 MB in 4s (21.7 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_99.0.4844.51-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_99.0.4844.51-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_99.0.4844.51-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_99.0.4844.51-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (99.0.4844.51-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "\n",
        "def createDirectory(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print(\"Error: Failed to create the directory.\")\n",
        "\n",
        "def crawling_img(name):\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')        # Head-less 설정\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver', options=options)\n",
        "    driver.get(\"https://www.google.co.kr/imghp?hl=ko&tab=wi&authuser=0&ogbl\")\n",
        "    elem = driver.find_element_by_name(\"q\")\n",
        "    elem.send_keys(name)\n",
        "    elem.send_keys(Keys.RETURN)\n",
        "\n",
        "    #\n",
        "    SCROLL_PAUSE_TIME = 1\n",
        "    # Get scroll height\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")  # 브라우저의 높이를 자바스크립트로 찾음\n",
        "    while True:\n",
        "        # Scroll down to bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  # 브라우저 끝까지 스크롤을 내림\n",
        "        # Wait to load page\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "        # Calculate new scroll height and compare with last scroll height\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            try:\n",
        "                driver.find_element_by_css_selector(\".mye4qd\").click()\n",
        "            except:\n",
        "                break\n",
        "        last_height = new_height\n",
        "\n",
        "    imgs = driver.find_elements_by_css_selector(\".rg_i.Q4LuWd\")\n",
        "    dir = \".\\idols\" + \"\\\\\" + name\n",
        "\n",
        "    createDirectory(dir) #폴더 생성\n",
        "    count = 1\n",
        "    for img in imgs:\n",
        "        try:\n",
        "            img.click()\n",
        "            time.sleep(2)\n",
        "            imgUrl = driver.find_element_by_xpath(\n",
        "                '//*[@id=\"Sva75c\"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img').get_attribute(\n",
        "                \"src\")\n",
        "            path = \"/content/drive/MyDrive/archive (5)/중장비\\\\\" + name + \"\\\\\"\n",
        "            urllib.request.urlretrieve(imgUrl, path + name + str(count) + \".jpg\")\n",
        "            count = count + 1\n",
        "            if count >= 260:\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "    driver.close()\n",
        "idols = [\"중장비\"]\n",
        "\n",
        "for idol in idols:\n",
        "    crawling_img(idol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYhHUIfFOjF0",
        "outputId": "e7913c77-dabd-4cbe-e77e-58cdd9100759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: find_element_by_name is deprecated. Please use find_element(by=By.NAME, value=name) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: find_elements_by_css_selector is deprecated. Please use find_elements(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "\n",
        "def createDirectory(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print(\"Error: Failed to create the directory.\")\n",
        "\n",
        "def crawling_img(name):\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')        # Head-less 설정\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver', options=options)\n",
        "    driver.get(\"https://www.google.co.kr/imghp?hl=ko&tab=wi&authuser=0&ogbl\")\n",
        "    elem = driver.find_element_by_name(\"q\")\n",
        "    elem.send_keys(name)\n",
        "    elem.send_keys(Keys.RETURN)\n",
        "\n",
        "    #\n",
        "    SCROLL_PAUSE_TIME = 1\n",
        "    # Get scroll height\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")  # 브라우저의 높이를 자바스크립트로 찾음\n",
        "    while True:\n",
        "        # Scroll down to bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  # 브라우저 끝까지 스크롤을 내림\n",
        "        # Wait to load page\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "        # Calculate new scroll height and compare with last scroll height\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            try:\n",
        "                driver.find_element_by_css_selector(\".mye4qd\").click()\n",
        "            except:\n",
        "                break\n",
        "        last_height = new_height\n",
        "\n",
        "    imgs = driver.find_elements_by_css_selector(\".rg_i.Q4LuWd\")\n",
        "    dir = \".\\idols\" + \"\\\\\" + name\n",
        "\n",
        "    createDirectory(dir) #폴더 생성\n",
        "    count = 1\n",
        "    for img in imgs:\n",
        "        try:\n",
        "            img.click()\n",
        "            time.sleep(2)\n",
        "            imgUrl = driver.find_element_by_xpath(\n",
        "                '//*[@id=\"Sva75c\"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img').get_attribute(\n",
        "                \"src\")\n",
        "            path = \"/content/drive/MyDrive/archive (5)/중장비\\\\\" + name + \"\\\\\"\n",
        "            urllib.request.urlretrieve(imgUrl, path + name + str(count) + \".jpg\")\n",
        "            count = count + 1\n",
        "            if count >= 50:\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "    driver.close()\n",
        "idols = [\"KTX\"]\n",
        "\n",
        "for idol in idols:\n",
        "    crawling_img(idol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX6zF1rHO65k",
        "outputId": "efcf91b8-15c9-452d-c5bf-a444e487bc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: find_element_by_name is deprecated. Please use find_element(by=By.NAME, value=name) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: find_elements_by_css_selector is deprecated. Please use find_elements(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "\n",
        "def createDirectory(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print(\"Error: Failed to create the directory.\")\n",
        "\n",
        "def crawling_img(name):\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')        # Head-less 설정\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver', options=options)\n",
        "    driver.get(\"https://www.google.co.kr/imghp?hl=ko&tab=wi&authuser=0&ogbl\")\n",
        "    elem = driver.find_element_by_name(\"q\")\n",
        "    elem.send_keys(name)\n",
        "    elem.send_keys(Keys.RETURN)\n",
        "\n",
        "    #\n",
        "    SCROLL_PAUSE_TIME = 1\n",
        "    # Get scroll height\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")  # 브라우저의 높이를 자바스크립트로 찾음\n",
        "    while True:\n",
        "        # Scroll down to bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  # 브라우저 끝까지 스크롤을 내림\n",
        "        # Wait to load page\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "        # Calculate new scroll height and compare with last scroll height\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            try:\n",
        "                driver.find_element_by_css_selector(\".mye4qd\").click()\n",
        "            except:\n",
        "                break\n",
        "        last_height = new_height\n",
        "\n",
        "    imgs = driver.find_elements_by_css_selector(\".rg_i.Q4LuWd\")\n",
        "    dir = \".\\idols\" + \"\\\\\" + name\n",
        "\n",
        "    createDirectory(dir) #폴더 생성\n",
        "    count = 1\n",
        "    for img in imgs:\n",
        "        try:\n",
        "            img.click()\n",
        "            time.sleep(2)\n",
        "            imgUrl = driver.find_element_by_xpath(\n",
        "                '//*[@id=\"Sva75c\"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img').get_attribute(\n",
        "                \"src\")\n",
        "            path = \"/content/drive/MyDrive/archive (5)/중장비\\\\\" + name + \"\\\\\"\n",
        "            urllib.request.urlretrieve(imgUrl, path + name + str(count) + \".jpg\")\n",
        "            count = count + 1\n",
        "            if count >= 50:\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "    driver.close()\n",
        "idols = [\"새마을호\"]\n",
        "\n",
        "for idol in idols:\n",
        "    crawling_img(idol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDkinkAJUZO6",
        "outputId": "8b4c4b5e-ec2f-4369-ffec-f3886bc9ccaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: find_element_by_name is deprecated. Please use find_element(by=By.NAME, value=name) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: find_element_by_css_selector is deprecated. Please use find_element(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: find_elements_by_css_selector is deprecated. Please use find_elements(by=By.CSS_SELECTOR, value=css_selector) instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PRhMd_2McolT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}